{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('sentence_bank.sqlite3')\n",
    "cursor = conn.cursor()\n",
    "cursor2 = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sentences for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ner.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip() == '':\n",
    "            sentences.append([])\n",
    "        else:\n",
    "            sentences[-1].append(line.split())\n",
    "            \n",
    "sentences.pop()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences) == 3655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    assert len(sentence) > 0\n",
    "    for word, tag in sentence:\n",
    "        assert tag in ['D', 'T', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: 4889 occurrences in 1644 sentences\n",
      "T: 3821 occurrences in 1183 sentences\n",
      "O: 55810 occurrences\n",
      "1843 sentences have neither D nor T, that's 50.42%!\n"
     ]
    }
   ],
   "source": [
    "D_count = 0\n",
    "T_count = 0\n",
    "O_count = 0\n",
    "D_scount = 0\n",
    "T_scount = 0\n",
    "neither_scount = 0\n",
    "\n",
    "for sentence in sentences:\n",
    "    D_found = False\n",
    "    T_found = False\n",
    "    \n",
    "    for word, tag in sentence:\n",
    "        if tag == 'D':\n",
    "            D_count += 1\n",
    "            D_found = True\n",
    "        elif tag == 'T':\n",
    "            T_count += 1\n",
    "            T_found = True\n",
    "        else:\n",
    "            O_count += 1\n",
    "    \n",
    "    if D_found:\n",
    "        D_scount += 1\n",
    "    if T_found:\n",
    "        T_scount += 1\n",
    "    if not D_found and not T_found:\n",
    "        neither_scount += 1\n",
    "    \n",
    "print 'D:', D_count, 'occurrences in', D_scount, 'sentences'\n",
    "print 'T:', T_count, 'occurrences in', T_scount, 'sentences'\n",
    "print 'O:', O_count, 'occurrences'\n",
    "print neither_scount, 'sentences have neither D nor T, that\\'s', '%.2f%%!' % (float(neither_scount)/36.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8650030998140111"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_count/float(D_count + T_count + O_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE sentences;')\n",
    "cursor.execute('DROP TABLE words;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS sentences (\n",
    "   id INTEGER PRIMARY KEY AUTOINCREMENT\n",
    ");''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS words (\n",
    "   sentence_id INTEGER,\n",
    "   word_id INTEGER,\n",
    "   word VARCHAR,\n",
    "   tag CHARACTER(1),\n",
    "   FOREIGN KEY(sentence_id) REFERENCES sentence(id),\n",
    "   PRIMARY KEY(sentence_id, word_id)\n",
    ");''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    cursor.execute('INSERT INTO sentences (id) VALUES (NULL);')\n",
    "    sentence_id = cursor.lastrowid\n",
    "    \n",
    "    for i, word_tag in enumerate(sentence):\n",
    "        word, tag = word_tag\n",
    "        assert tag in ['D', 'T', 'O']\n",
    "        \n",
    "        cursor.execute('INSERT INTO words (sentence_id, word_id, word, tag) VALUES (?, ?, ?, ?);',\n",
    "                       (sentence_id, i, word.decode('utf8', 'ignore'), tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print '[Actual]'\n",
    "print 'Sentences:', sentence_id\n",
    "print 'Words:    ', cursor.lastrowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print '[Expected]'\n",
    "print 'Sentences:', len(sentences)\n",
    "print 'Words:    ', sum(map(len, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DELETE FROM pos_tags;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS pos_tags (\n",
    "   sentence_id INTEGER,\n",
    "   word_id INTEGER,\n",
    "   pos_tag VARCHAR,\n",
    "   FOREIGN KEY(sentence_id, word_id) REFERENCES words(sentence_id, word_id),\n",
    "   PRIMARY KEY(sentence_id, word_id)\n",
    ");''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM sentences;')\n",
    "\n",
    "for row in cursor:\n",
    "    sentence_id = row[0]\n",
    "    cursor2.execute('SELECT word_id, word FROM words WHERE sentence_id = ? ORDER BY word_id', (sentence_id,))\n",
    "    \n",
    "    sentence = []\n",
    "    \n",
    "    for i, row2 in enumerate(cursor2):\n",
    "        word_id, word = row2\n",
    "        assert i == word_id\n",
    "        sentence.append(word)\n",
    "    \n",
    "    tags = nltk.pos_tag(sentence)\n",
    "    \n",
    "    for i, word_tag in enumerate(tags):\n",
    "        word, pos_tag = word_tag\n",
    "        cursor2.execute('INSERT INTO pos_tags (sentence_id, word_id, pos_tag) VALUES (?, ?, ?);',\n",
    "                       (sentence_id, i, pos_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43,)\n"
     ]
    }
   ],
   "source": [
    "for row in cursor.execute('SELECT COUNT(DISTINCT pos_tag) FROM pos_tags;'):\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyponyms(concept, stringify=True):\n",
    "    concept = wn.synset(concept)\n",
    "    hyponyms = set([i for i in concept.closure(lambda s:s.hyponyms())])\n",
    "    \n",
    "    if stringify:\n",
    "        hyponyms = set([str(hyponym)[8:-7].replace('_', ' ') for hyponym in hyponyms])\n",
    "    \n",
    "    assert type(hyponyms) == set\n",
    "    return hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DELETE FROM wordnet_tags;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS wordnet_tags (\n",
    "   sentence_id INTEGER,\n",
    "   word_id INTEGER,\n",
    "   wordnet_tag VARCHAR,\n",
    "   FOREIGN KEY(sentence_id, word_id) REFERENCES words(sentence_id, word_id),\n",
    "   PRIMARY KEY(sentence_id, word_id, wordnet_tag)\n",
    ");''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_of_interest = ['body_part.n.01', 'medicine.n.01', 'treatment.n.01', 'disease.n.01', 'chemical.n.01']\n",
    "hyponyms = dict([(concept, get_hyponyms(concept)) for concept in concepts_of_interest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM sentences;')\n",
    "\n",
    "for row in cursor:\n",
    "    sentence_id = row[0]\n",
    "    cursor2.execute('SELECT word_id, word FROM words WHERE sentence_id = ? ORDER BY word_id', (sentence_id,))\n",
    "    \n",
    "    sentence = []\n",
    "    \n",
    "    for i, row2 in enumerate(cursor2):\n",
    "        word_id, word = row2\n",
    "        assert i == word_id\n",
    "        sentence.append(word)\n",
    "    \n",
    "    sentence_lower = [w.lower() for w in sentence]\n",
    "    tags = []\n",
    "\n",
    "    for concept in concepts_of_interest:\n",
    "        for hyponym in hyponyms[concept]:\n",
    "            hyponym = hyponym.split()\n",
    "\n",
    "            for i in range(len(sentence) - len(hyponym) + 1):\n",
    "                if sentence_lower[i:i+len(hyponym)] == hyponym:\n",
    "                    tags += [(i, i+len(hyponym), concept)]\n",
    "    \n",
    "    for tag in tags:\n",
    "        start, end, wordnet_tag = tag\n",
    "\n",
    "        for word_id in range(start, end):\n",
    "            cursor2.execute('INSERT OR IGNORE INTO wordnet_tags (sentence_id, word_id, wordnet_tag) VALUES (?, ?, ?);',\n",
    "                       (sentence_id, word_id, wordnet_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in concepts_of_interest:\n",
    "    print '\\033[1m[%s:' % (concept,),\n",
    "    \n",
    "    for row in cursor.execute('SELECT COUNT(*) FROM wordnet_tags WHERE wordnet_tag = ?;', (concept,)):\n",
    "        print row[0], '(total)]', '\\033[0;0m'\n",
    "        \n",
    "    # Check the corresponding labels of tags!\n",
    "    for row in cursor2.execute('''\n",
    "    SELECT tag, COUNT(*) FROM words INNER JOIN wordnet_tags\n",
    "    ON words.sentence_id = wordnet_tags.sentence_id\n",
    "    AND words.word_id = wordnet_tags.word_id\n",
    "    WHERE wordnet_tag = ?\n",
    "    GROUP BY tag;\n",
    "    ''', (concept,)):\n",
    "        print '%s: %d' % row\n",
    "        \n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeSH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_comma(word):\n",
    "    if ',' in word and ',' not in word[word.index(',') + 1:]:\n",
    "        return (word[word.index(',') + 1:] + ' ' + word[:word.index(',')]).strip()\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifiers = dict()\n",
    "\n",
    "with open('q2018.bin', 'r') as f:\n",
    "    subject_heading = None\n",
    "    \n",
    "    for line in f:\n",
    "        if line.strip() in ['', '*NEWRECORD']:\n",
    "            subject_heading = None\n",
    "            continue\n",
    "        else:\n",
    "            key, label = line.split(' = ', 1)\n",
    "        \n",
    "        if key == 'SH':\n",
    "            subject_heading = fix_comma(label.strip().lower())\n",
    "            qualifiers[subject_heading] = set()\n",
    "        elif key == 'QX':\n",
    "            qualifiers[subject_heading].add(fix_comma(label.split('|')[0].strip().lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = dict()\n",
    "\n",
    "with open('d2018.bin', 'r') as f:\n",
    "    subject_heading = None\n",
    "    \n",
    "    for line in f:\n",
    "        if line.strip() in ['', '*NEWRECORD']:\n",
    "            subject_heading = None\n",
    "            continue\n",
    "        else:\n",
    "            key, label = line.split(' = ', 1)\n",
    "        \n",
    "        if key == 'MH':\n",
    "            subject_heading = fix_comma(label.strip().lower())\n",
    "            descriptors[subject_heading] = set()\n",
    "        elif key == 'ENTRY':\n",
    "            descriptors[subject_heading].add(fix_comma(label.split('|')[0].strip().lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qualifiers  = [[k] + list(v) for k,v in qualifiers.iteritems() ]\n",
    "all_descriptors = [[k] + list(v) for k,v in descriptors.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qualifiers  = set().union(*all_qualifiers)\n",
    "all_descriptors = set().union(*all_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_qualifier_map  = dict(set().union(*[[(v1, k) for v1 in v] + [(k, k)] for k, v in qualifiers.iteritems()]))\n",
    "reverse_descriptor_map = dict(set().union(*[[(v1, k) for v1 in v] + [(k, k)] for k, v in descriptors.iteritems()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fd704631d50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('DROP TABLE mesh_tags;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fd704631d50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS mesh_tags (\n",
    "   sentence_id INTEGER,\n",
    "   word_id INTEGER,\n",
    "   mesh_type VARCHAR,\n",
    "   mesh_keyword VARCHAR,\n",
    "   FOREIGN KEY(sentence_id, word_id) REFERENCES words(sentence_id, word_id),\n",
    "   PRIMARY KEY(sentence_id, word_id, mesh_type, mesh_keyword)\n",
    ");''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117241\n"
     ]
    }
   ],
   "source": [
    "num_in = 0\n",
    "to_remove = set()\n",
    "\n",
    "for word in all_descriptors:\n",
    "    if '0' in word or '1' in word or '2' in word or '3' in word or '4' in word or '(' in word or \\\n",
    "       '5' in word or '6' in word or '7' in word or '8' in word or '9' in word or '%' in word:\n",
    "        to_remove.add(word)\n",
    "\n",
    "for word in to_remove:\n",
    "    all_descriptors.remove(word)\n",
    "\n",
    "print len(all_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM sentences;')\n",
    "\n",
    "for row in cursor:\n",
    "    sentence_id = row[0]\n",
    "    cursor2.execute('SELECT word_id, word FROM words WHERE sentence_id = ? ORDER BY word_id', (sentence_id,))\n",
    "    \n",
    "    sentence = []\n",
    "    \n",
    "    for i, row2 in enumerate(cursor2):\n",
    "        word_id, word = row2\n",
    "        assert i == word_id\n",
    "        sentence.append(word)\n",
    "    \n",
    "    sentence_lower = [w.lower() for w in sentence]\n",
    "    tags = []\n",
    "\n",
    "    for qualifier in all_qualifiers:\n",
    "        og_qualifier = qualifier\n",
    "        qualifier = qualifier.split()\n",
    "\n",
    "        for i in range(len(sentence) - len(qualifier) + 1):\n",
    "            if sentence_lower[i:i+len(qualifier)] == qualifier:\n",
    "                tags += [(i, i+len(qualifier), 'qualifier', reverse_qualifier_map[og_qualifier])]\n",
    "                    \n",
    "    for tag in tags:\n",
    "        start, end, mesh_type, mesh_tag = tag\n",
    "\n",
    "        for word_id in range(start, end):\n",
    "            cursor2.execute('INSERT OR IGNORE INTO mesh_tags (sentence_id, word_id, mesh_type, mesh_keyword) VALUES (?, ?, ?, ?);',\n",
    "                       (sentence_id, word_id, mesh_type, mesh_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And... we're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
