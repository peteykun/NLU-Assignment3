{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('sentence_bank.sqlite3')\n",
    "cursor = conn.cursor()\n",
    "cursor2 = conn.cursor()\n",
    "cursor3 = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT id FROM sentences ORDER BY id;')\n",
    "sentence_ids = []\n",
    "\n",
    "for row in cursor:\n",
    "    sentence_ids += [row[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "train = list(np.random.choice(sentence_ids, size=int(len(sentence_ids)*0.7), replace=False))\n",
    "valid = np.random.choice(list(set(sentence_ids) - set(train)), size=int(len(sentence_ids)*0.1), replace=False)\n",
    "test = list(set(sentence_ids) - set(train) - set(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 2558 365 732\n",
      "3655\n"
     ]
    }
   ],
   "source": [
    "print 'Splits:', len(train), len(valid), len(test)\n",
    "print len(sentence_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare vocabulary\n",
    "vocabulary = ['@@PAD@@', '@@SOS@@', '@@EOS@@']\n",
    "\n",
    "for word, count in cursor.execute('SELECT DISTINCT LOWER(word), COUNT(LOWER(word)) FROM words GROUP BY word ORDER BY COUNT(LOWER(word)) DESC;'):\n",
    "    vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_vocab_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restrict_vocab_size is not None:\n",
    "    vocabulary = vocabulary[:restrict_vocab_size]\n",
    "    vocabulary.append('@@OOV@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11120"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_fwd = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "dictionary_bwd = dict(zip(range(len(vocabulary)), vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['O', 'T', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_out_fwd = dict(zip(labels, range(len(labels))))\n",
    "dictionary_out_bwd = dict(zip(range(len(labels)), labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "train_l = []\n",
    "\n",
    "valid_x = []\n",
    "valid_y = []\n",
    "valid_l = []\n",
    "\n",
    "test_x  = []\n",
    "test_y  = []\n",
    "test_l  = []\n",
    "\n",
    "for sentence_id, in cursor.execute('SELECT * FROM sentences;'):\n",
    "    sentence = []\n",
    "    cursor2.execute('''\n",
    "    SELECT LOWER(word), tag\n",
    "    FROM words\n",
    "    JOIN pos_tags ON words.sentence_id = pos_tags.sentence_id AND words.word_id = pos_tags.word_id                       \n",
    "    WHERE words.sentence_id = ? ORDER BY words.word_id''', (sentence_id,))\n",
    "    \n",
    "    x = [dictionary_fwd['@@SOS@@']]\n",
    "    y = [dictionary_out_fwd['O']]\n",
    "    l = 1\n",
    "    \n",
    "    for row in cursor2:        \n",
    "        x.append(dictionary_fwd[row[0]])\n",
    "        y.append(dictionary_out_fwd[row[1]])\n",
    "        l += 1\n",
    "        \n",
    "    x.append(dictionary_fwd['@@EOS@@'])\n",
    "    y.append(dictionary_out_fwd['O'])\n",
    "    l += 1\n",
    "    \n",
    "    if sentence_id in train:\n",
    "        train_x.append(x)\n",
    "        train_y.append(y)\n",
    "        train_l.append(l)\n",
    "    if sentence_id in valid:\n",
    "        valid_x.append(x)\n",
    "        valid_y.append(y)\n",
    "        valid_l.append(l)\n",
    "    if sentence_id in test:\n",
    "        test_x.append(x)\n",
    "        test_y.append(y)\n",
    "        test_l.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max(map(len, train_x) + map(len, valid_x) + map(len, test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_x)):\n",
    "    #train_x[i] = [0] * (maxlen - len(train_x[i])) + train_x[i]\n",
    "    train_y[i] = [0] * (maxlen - len(train_y[i])) + train_y[i]\n",
    "    \n",
    "for i in range(len(valid_x)):\n",
    "    #valid_x[i] = [0] * (maxlen - len(valid_x[i])) + valid_x[i]\n",
    "    valid_y[i] = [0] * (maxlen - len(valid_y[i])) + valid_y[i]\n",
    "    \n",
    "for i in range(len(test_x)):\n",
    "    #test_x[i] = [0] * (maxlen - len(test_x[i])) + test_x[i]\n",
    "    test_y[i] = [0] * (maxlen - len(test_y[i])) + test_y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, valid_x, valid_y, test_x, test_y = np.array(train_x), np.array(train_y), np.array(valid_x), np.array(valid_y), np.array(test_x), np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_x.npy', train_x); np.save('train_y.npy', train_y); np.save('train_l.npy', train_l)\n",
    "np.save('valid_x.npy', valid_x); np.save('valid_y.npy', valid_y); np.save('valid_l.npy', valid_l)\n",
    "np.save('test_x.npy', test_x); np.save('test_y.npy', test_y); np.save('test_l.npy', test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dictionary_fwd.npy', dictionary_fwd)\n",
    "np.save('dictionary_bwd.npy', dictionary_bwd)\n",
    "np.save('dictionary_out_fwd.npy', dictionary_out_fwd)\n",
    "np.save('dictionary_out_bwd.npy', dictionary_out_bwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
